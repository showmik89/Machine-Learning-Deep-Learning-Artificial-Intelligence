# -*- coding: utf-8 -*-
"""Bert.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ogfrkOP8PWhSiuf92EwuOXFxI7ko3yKP
"""

pip install tensorflow-text

pip install transformers

import pandas as pd
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
from transformers import BertTokenizer, TFBertForSequenceClassification
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix
from sklearn.utils import shuffle

# Load the data
df = pd.read_csv('AI_Content_Detection - Binary_Classification.csv')

# Split the data into training and testing sets
X = df['content']
y = df['class']
X, y = shuffle(X, y, random_state=42)  # Shuffle the data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize the BERT tokenizer
tokenizer = BertTokenizer.from_pretrained("bert-base-uncased")

# Tokenize and preprocess the data
max_sequence_length = 100  # You can adjust this value as needed
X_train_encoded = tokenizer(list(X_train), truncation=True, padding=True, return_tensors="tf", max_length=max_sequence_length)
X_test_encoded = tokenizer(list(X_test), truncation=True, padding=True, return_tensors="tf", max_length=max_sequence_length)

# Convert labels to numpy arrays
y_train = np.array(y_train)
y_test = np.array(y_test)

# Load the pretrained BERT model for sequence classification
model = TFBertForSequenceClassification.from_pretrained("bert-base-uncased", num_labels=1)

# Compile the model
optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5)
model.compile(optimizer=optimizer, loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), metrics=['accuracy'])

# Train the model
history = model.fit(
    X_train_encoded.data,
    y_train,
    epochs=20,  # You can adjust the number of epochs
    batch_size=32,
    validation_split=0.1
)

# Evaluate the model on the test data
results = model.evaluate(X_test_encoded.data, y_test, batch_size=32)

# Extract the accuracy from the results
accuracy = results[1]

# Print the final accuracy
print("Final Accuracy:", accuracy)

import matplotlib.pyplot as plt

# Plot training history (accuracy and loss)
plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.title('Accuracy vs. Epochs')

plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.title('Loss vs. Epochs')

plt.tight_layout()
plt.show()

# Calculate confusion matrix
y_pred_logits = model.predict(X_test_encoded.data)
y_pred = (y_pred_logits.logits > 0).astype(int)  # Apply a threshold to convert logits to binary predictions

conf_matrix = confusion_matrix(y_test, y_pred)

print("Confusion Matrix:")
print(conf_matrix)

import matplotlib.pyplot as plt
import seaborn as sns

# Calculate confusion matrix
y_pred_logits = model.predict(X_test_encoded.data)
y_pred = (y_pred_logits.logits > 0).astype(int)  # Apply a threshold to convert logits to binary predictions

conf_matrix = confusion_matrix(y_test, y_pred)

# Create a heatmap for the confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()

# Evaluate the model on the test data
results = model.evaluate(X_test_encoded.data, y_test, batch_size=32)

# Extract the accuracy from the results
testing_accuracy = results[1]

# Print the testing accuracy
print("Testing Accuracy:", testing_accuracy)

# Evaluate the model on the test data
results = model.evaluate(X_test_encoded.data, y_test, batch_size=32)

# Extract the training accuracy and testing accuracy from the results
training_accuracy = history.history['accuracy'][-1]
testing_accuracy = results[1]

# Print both training and testing accuracies
print("Training Accuracy:", training_accuracy)
print("Testing Accuracy:", testing_accuracy)

# Plot training accuracy
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.title('Training Accuracy vs. Epochs')
plt.legend()
plt.show()

# Plot both training and testing accuracy on the same graph
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot([len(history.history['accuracy'])], [testing_accuracy], 'ro', label='Testing Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.title('Training and Testing Accuracy vs. Epochs')
plt.legend()
plt.show()
