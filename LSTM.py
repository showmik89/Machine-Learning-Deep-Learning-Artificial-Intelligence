# -*- coding: utf-8 -*-
"""Untitled167.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1I3HOgE0DpKh32EDxcczhz-fEri8chOME
"""

import pandas as pd
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, classification_report
from tensorflow.keras.metrics import TruePositives, TrueNegatives, FalsePositives, FalseNegatives

# Load your CSV data
df = pd.read_csv('AI_Content_Detection - Binary_Classification.csv')

# Split the data into training and testing sets
X = df['content']
y = df['class']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Tokenize data
tokenizer = Tokenizer(num_words=5000, oov_token="<OOV>")
tokenizer.fit_on_texts(X_train)
X_train_seq = tokenizer.texts_to_sequences(X_train)
X_test_seq = tokenizer.texts_to_sequences(X_test)

# Pad sequences to have the same length
max_sequence_length = 100  # Choose an appropriate value based on your data
X_train_padded = pad_sequences(X_train_seq, maxlen=max_sequence_length, padding='post', truncating='post')
X_test_padded = pad_sequences(X_test_seq, maxlen=max_sequence_length, padding='post', truncating='post')

model = Sequential([
    Embedding(input_dim=5000, output_dim=64, input_length=max_sequence_length),
    LSTM(64, return_sequences=True),
    LSTM(64),
    Dense(64, activation='relu'),
    Dropout(0.5),
    Dense(1, activation='sigmoid')
])

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Print a summary of the model architecture
model.summary()

history = model.fit(
    X_train_padded, y_train,
    validation_data=(X_test_padded, y_test),
    epochs=100,
    batch_size=32
)

# Get predictions
y_pred = model.predict(X_test_padded)

# Convert predictions to binary labels (0 or 1)
y_pred_binary = [1 if pred > 0.5 else 0 for pred in y_pred]

# Calculate confusion matrix
conf_matrix = confusion_matrix(y_test, y_pred_binary)

# Calculate precision, recall, and F1 score
true_positives = TruePositives()(y_test, y_pred)
true_negatives = TrueNegatives()(y_test, y_pred)
false_positives = FalsePositives()(y_test, y_pred)
false_negatives = FalseNegatives()(y_test, y_pred)

precision = true_positives / (true_positives + false_positives)
recall = true_positives / (true_positives + false_negatives)
f1_score = 2 * (precision * recall) / (precision + recall)

print("Confusion Matrix:")
print(conf_matrix)
print("\nClassification Report:")
print(classification_report(y_test, y_pred_binary))
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"F1 Score: {f1_score:.4f}")



# Get testing accuracy
test_accuracy = history.history['val_accuracy'][-1]

# Calculate confusion matrix
conf_matrix = confusion_matrix(y_test, y_pred_binary)

# Calculate precision, recall, and F1 score
true_positives = TruePositives()(y_test, y_pred)
true_negatives = TrueNegatives()(y_test, y_pred)
false_positives = FalsePositives()(y_test, y_pred)
false_negatives = FalseNegatives()(y_test, y_pred)

precision = true_positives / (true_positives + false_positives)
recall = true_positives / (true_positives + false_negatives)
f1_score = 2 * (precision * recall) / (precision + recall)

print("Confusion Matrix:")
print(conf_matrix)
print("\nClassification Report:")
print(classification_report(y_test, y_pred_binary))
print(f"Testing Accuracy: {test_accuracy:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"F1 Score: {f1_score:.4f}")